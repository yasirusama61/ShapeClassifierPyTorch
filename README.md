# ğŸŸ¢ Shape Classifier (PyTorch)

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.13.1-%23EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Completed-brightgreen)]()

---

This project demonstrates the training and evaluation of a simple **CNN-based vision model** to classify geometric shapes â€” **Circle**, **Square**, and **Triangle** â€” using synthetic data generated with the Python `PIL` library.

The goal is to provide a clean, minimal baseline for beginners exploring deep learning in computer vision, especially with synthetic datasets.

---

## ğŸ“Œ Task Objective

Develop a basic shape classifier under different synthetic conditions:
- Fixed Length, Fixed Rotation âœ…
- Fixed Length, Random Rotation â³
- Random Length, Fixed Rotation â³
- Random Length, Random Rotation â³

---

## ğŸ§ª Current Status
| Condition Type | Implemented | Accuracy |
|----------------|-------------|----------|
| Fixed Length + Fixed Rotation | âœ… Done | 100% (Train / Val / Test) |

---

## ğŸ§  Model Summary

A simple CNN with 3 convolutional layers and 2 fully connected layers is used. It efficiently classifies synthetic shapes under the fixed size + rotation condition with 100% accuracy.

```python
Conv2d â†’ ReLU â†’ MaxPool  
Conv2d â†’ ReLU â†’ MaxPool  
Conv2d â†’ ReLU â†’ MaxPool  
Flatten â†’ FC â†’ ReLU â†’ FC (3 outputs)
```
---

## ğŸ“‚ Folder Structure

```
ShapeClassifierPyTorch/
â”œâ”€â”€ Shape_Classifier.ipynb         # ğŸ““ Main notebook for training and evaluation
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Dependencies for pip install
â”œâ”€â”€ README.md                      # ğŸ“˜ Project overview and instructions
â”œâ”€â”€ images/                        # ğŸ“· Visualizations for README
â”‚   â””â”€â”€ sample_preds.png
â”œâ”€â”€ data/                          # ğŸ–¼ï¸ Generated synthetic datasets
â”‚   â””â”€â”€ fixed_length_fixed_rotation/
â”‚       â”œâ”€â”€ circle/
â”‚       â”œâ”€â”€ square/
â”‚       â””â”€â”€ triangle/
â””â”€â”€ saved_models/                  # ğŸ’¾ (Optional) model checkpoints
```

## ğŸ–¼ï¸ Sample Dataset Visualization

### ğŸ“Š Example of Synthetic Shapes (Fixed Length, Fixed Rotation)

This figure shows a few randomly generated shapes from the dataset used to train the classifier:

<img src="images/sample_dataset.png" width="600"/>

---

## ğŸ“‰ Training Log Summary

The model was trained for 15 epochs using the Fixed Length + Fixed Rotation dataset. It converged very quickly due to the simplicity and clarity of the synthetic data.

**Device:** CUDA (GPU)  
**Loss Function:** CrossEntropyLoss  
**Optimizer:** Adam (lr = 0.001)  
**Batch Size:** 32  
**Epochs:** 15

**Training Summary:**
```
Using device: cuda
[Epoch 1/15] Train Loss: 0.3529 | Val Loss: 0.0000 | Val Acc: 100.00%
[Epoch 2/15] Train Loss: 0.0000 | Val Loss: 0.0000 | Val Acc: 100.00%
...
[Epoch 15/15] Train Loss: 0.0000 | Val Loss: 0.0000 | Val Acc: 100.00%
```

The model reached **100% accuracy on both training and validation** within 2 epochs and maintained it across all 15, showing perfect generalization under this condition.

### ğŸ“ˆ Loss Curve

Below is the training and validation loss plotted over all epochs:

<img src="images/loss_curve_fixed_fixed.png" width="600"/>

### ğŸ” Sample Predictions

Below are example predictions from our trained shape classification model. Each subplot shows the **ground truth (GT)** label and the **predicted (Pred)** label for a synthetic shape image.

![Sample Predictions](images/predictions_sample.png)

All predictions in this batch were correctly classified, demonstrating the modelâ€™s ability to generalize to unseen samples from the test set.

---

## ğŸŒ€ Fixed Length, Random Rotation

In this dataset variant, all geometric shapes maintain a **constant size**, but each shape is assigned a **random rotation angle** between 0Â° and 360Â°. This variation helps the model learn **rotation-invariant features** for better generalization.

### ğŸ–¼ï¸ Sample Images

Below are random samples from each shape class in the `fixed_length_random_rotation` dataset:

![Fixed Rotation](images/fixed_length_random_rotation_samples.png)

### âœ… Results: Fixed Length + Random Rotation

The model was trained on the `fixed_length_random_rotation` dataset using the same CNN architecture. All shapes were of fixed size, but randomly rotated. The model demonstrated excellent rotation-invariant classification ability.

**Test Accuracy:** `100.00% (225/225)`  
**Per-Class Accuracy:**
- Circle: 100% (73/73)
- Square: 100% (81/81)
- Triangle: 100% (71/71)

### ğŸ” Predictions Visualization

Below is a batch of test predictions showing perfect performance. Each image includes:
- **T**: True label
- **P**: Predicted label

<p align="center">
  <img src="images/fixed_length_random_rotation_preds.png" alt="Fixed Rotation Predictions" width="90%">
</p>

---

We observed that the model generalized well to rotated versions of shapes even though trained only on fixed-size inputs, suggesting robustness to geometric transformations. Further experiments will explore variable-length and noise-augmented datasets.

## ğŸ§ª Random Length + Fixed Rotation

In this experimental condition, each geometric shape (Circle, Square, Triangle) is generated with a **random size**, but the **rotation angle is fixed** across all samples (e.g., 45Â°). This setup evaluates the modelâ€™s ability to generalize across different scales while preserving a consistent orientation.

### âš™ï¸ Characteristics
- **Length (size):** Randomized per image (range: 20â€“50 pixels)
- **Rotation:** Fixed (e.g., 45Â°)
- **Total samples per class:** 500 (balanced)
- **Image size:** 128Ã—128 px

### ğŸ–¼ï¸ Sample Images

Below are random samples from each class in the `random_length_fixed_rotation` dataset:

<p align="center">
  <img src="images/random_length_fixed_rotation_samples.png" alt="Random Length + Fixed Rotation Samples" width="90%">
</p>

This visual confirms that the model must learn **scale-invariant** features, as shapes of different sizes appear throughout the dataset while maintaining orientation.

---
